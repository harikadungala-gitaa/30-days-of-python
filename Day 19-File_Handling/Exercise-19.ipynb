{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bad618d",
   "metadata": {},
   "source": [
    "LEVEL-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f67c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 19: 30 Days of Python - File Handling and Text Analysis\n",
    "\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# -----------------------------\n",
    "#  Exercise Level 1\n",
    "# -----------------------------\n",
    "\n",
    "# Count number of lines and words in a text file\n",
    "def count_lines_and_words(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        lines = text.splitlines()\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        return len(lines), len(words)\n",
    "\n",
    "\n",
    "files = [\n",
    "    './data/obama_speech.txt',\n",
    "    './data/michelle_obama_speech.txt',\n",
    "    './data/donald_speech.txt',\n",
    "    './data/melina_trump_speech.txt'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    lines, words = count_lines_and_words(file)\n",
    "    print(f\"{file}: {lines} lines, {words} words\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Most spoken languages\n",
    "# -----------------------------\n",
    "\n",
    "def most_spoken_languages(filename, top_n):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        countries = json.load(f)\n",
    "    languages = []\n",
    "    for country in countries:\n",
    "        languages.extend(country['languages'])\n",
    "    lang_counts = Counter(languages)\n",
    "    return lang_counts.most_common(top_n)\n",
    "\n",
    "\n",
    "print(\"\\nMost spoken languages (top 10):\")\n",
    "print(most_spoken_languages('./data/countries_data.json', 10))\n",
    "\n",
    "print(\"\\nMost spoken languages (top 3):\")\n",
    "print(most_spoken_languages('./data/countries_data.json', 3))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Most populated countries\n",
    "# -----------------------------\n",
    "\n",
    "def most_populated_countries(filename, top_n):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        countries = json.load(f)\n",
    "    sorted_countries = sorted(countries, key=lambda x: x['population'], reverse=True)\n",
    "    top_countries = [{'country': c['name'], 'population': c['population']} for c in sorted_countries[:top_n]]\n",
    "    return top_countries\n",
    "\n",
    "\n",
    "print(\"\\nMost populated countries (top 10):\")\n",
    "print(most_populated_countries('./data/countries_data.json', 10))\n",
    "\n",
    "print(\"\\nMost populated countries (top 3):\")\n",
    "print(most_populated_countries('./data/countries_data.json', 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275e82e",
   "metadata": {},
   "source": [
    "LEVEL-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6a075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Extract all email addresses\n",
    "# -----------------------------\n",
    "\n",
    "def extract_emails(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return re.findall(r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}', text)\n",
    "\n",
    "\n",
    "emails = extract_emails('./data/email_exchange_big.txt')\n",
    "print(\"\\nExtracted emails:\", emails[:10], '...')  # show first 10\n",
    "print(\"Total emails found:\", len(emails))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d888245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Most common words in a file\n",
    "# -----------------------------\n",
    "\n",
    "def find_most_common_words(filename, n):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().lower()\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        return Counter(words).most_common(n)\n",
    "\n",
    "\n",
    "print(\"\\nTop 10 words in sample.txt:\")\n",
    "print(find_most_common_words('./data/sample.txt', 10))\n",
    "\n",
    "print(\"\\nTop 5 words in sample.txt:\")\n",
    "print(find_most_common_words('./data/sample.txt', 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4dfe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Most frequent words in speeches\n",
    "# -----------------------------\n",
    "\n",
    "def most_frequent_words(filename, n=10):\n",
    "    return find_most_common_words(filename, n)\n",
    "\n",
    "print(\"\\nObama’s top 10 words:\", most_frequent_words('./data/obama_speech.txt'))\n",
    "print(\"Michelle’s top 10 words:\", most_frequent_words('./data/michelle_obama_speech.txt'))\n",
    "print(\"Trump’s top 10 words:\", most_frequent_words('./data/donald_speech.txt'))\n",
    "print(\"Melina’s top 10 words:\", most_frequent_words('./data/melina_trump_speech.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d9069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Text similarity\n",
    "# -----------------------------\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^A-Za-z\\s]', '', text).lower()\n",
    "\n",
    "def check_text_similarity(file1, file2):\n",
    "    with open(file1, 'r', encoding='utf-8') as f1, open(file2, 'r', encoding='utf-8') as f2:\n",
    "        text1, text2 = clean_text(f1.read()), clean_text(f2.read())\n",
    "    similarity = SequenceMatcher(None, text1, text2).ratio()\n",
    "    return round(similarity * 100, 2)\n",
    "\n",
    "\n",
    "similarity_score = check_text_similarity('./data/michelle_obama_speech.txt', './data/melina_trump_speech.txt')\n",
    "print(f\"\\nText similarity between Michelle and Melina speeches: {similarity_score}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9922e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Top repeated words in Romeo and Juliet\n",
    "# -----------------------------\n",
    "\n",
    "print(\"\\nTop 10 words in Romeo and Juliet:\")\n",
    "print(find_most_common_words('./data/romeo_and_juliet.txt', 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099879e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Hacker News CSV word frequency\n",
    "# -----------------------------\n",
    "\n",
    "def count_keyword_occurrences(filename, keyword):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    return sum(1 for line in lines if re.search(keyword, line, re.IGNORECASE))\n",
    "\n",
    "python_count = count_keyword_occurrences('./data/hacker_news.csv', r'\\bpython\\b')\n",
    "js_count = count_keyword_occurrences('./data/hacker_news.csv', r'\\bjavascript\\b')\n",
    "java_count = count_keyword_occurrences('./data/hacker_news.csv', r'\\bjava\\b(?!script)')\n",
    "\n",
    "print(\"\\nLines containing 'Python':\", python_count)\n",
    "print(\"Lines containing 'JavaScript':\", js_count)\n",
    "print(\"Lines containing 'Java' but not 'JavaScript':\", java_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
